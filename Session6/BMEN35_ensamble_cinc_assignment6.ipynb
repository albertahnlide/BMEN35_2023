{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35_2023/blob/main/Session6/BMEN35_ensamble_cinc_assignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkiFi80bGKEc"
      },
      "source": [
        "# Assignment 6\n",
        "## Fill in your name below\n",
        "Albert Ahnlide\n",
        "\n",
        "## Your mission is now the following:\n",
        "\n",
        "You will use data from the Computing in Cardiology challenge 2022 (as was explained in the lectures) (https://moody-challenge.physionet.org/2022/). The training set contains data from 942 patients.\n",
        "\n",
        "We have done some preprocessing of the data so you have features and labels for both **murmur** and **outcome**. The features include age, sex, weight, heigth, pregnancy status and mean, variance and skewness for the phonocardiogram at five different locations.\n",
        "\n",
        "Evaluate different ensamble methods (at least 3) from sklearn (https://scikit-learn.org/stable/modules/ensemble.html and https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble) and see how they perform on the CinC2022 challenge data. Take some time to read the documentation and see what options are available.\n",
        "\n",
        "As you may remember from the lecture there is quite an eloborate scoring scheme, however this is handled by the file cinc2022metric.py and the methods contained therein.\n",
        "\n",
        "**Also remeber you have two sets of labels!!! One set of labels for murmurs (Present, Unknown, Absent) and one for outcomes (Abnormal, Normal).**\n",
        "\n",
        "**Another thing you need to take into account is that the scoring functions need label probabilities of the predicted classes.**\n",
        "\n",
        "You will also need one-hot encoding of \"hard\" values for the training labels and for the test labels.\n",
        "\n",
        "We will start by uploading some files. You need to upload the files cinc2022metrics.py, feats.csv, murmur_labels.csv and outcome_labels.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRiQuM1OHKQR"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#_ = files.upload() # Upload the other files available in github under Session 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YbyBrB9MKBW"
      },
      "source": [
        "Next we will import some of the libraries/modules needed. (You will need to import others later on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SJx0_S_GMLfV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/albertahnlide/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cinc2022metrics as cm # Our own little metrics file\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgS-HYV4MWn3"
      },
      "source": [
        "Next we will import data and the two different sets of labels and switch to numpy arrays.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NXy1fcB8Mah0"
      },
      "outputs": [],
      "source": [
        "feats = pd.read_csv('feats.csv', header=None)\n",
        "murmur_labels = pd.read_csv('murmur_labels.csv', header=None)\n",
        "outcome_labels = pd.read_csv('outcome_labels.csv', header=None)\n",
        "\n",
        "feats = feats.to_numpy()\n",
        "murmur_labels = murmur_labels.to_numpy()\n",
        "outcome_labels = outcome_labels.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6AjJag6bbYG"
      },
      "source": [
        "Here we will split the data and also define what the different classes for murmur and outcome are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DYFYliDGNCl0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train_murmur, y_test_murmur, y_train_outcome, y_test_outcome = train_test_split(feats, murmur_labels, outcome_labels, test_size=0.2, random_state=0)\n",
        "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
        "outcome_classes = ['Abnormal', 'Normal']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AaRI3joNGvd"
      },
      "source": [
        "Next you can try out some of the available ensemble methods. Remember you need to predict probabilities for both classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FT0zGggANGIW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/albertahnlide/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GradientBoostingClassifier(random_state=0)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Do some imports (you now how to do this by now)\n",
        "from sklearn.ensemble import GradientBoostingClassifier as es # Change questionmarks to something you want to test.\n",
        "\n",
        "# Create the model \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MzLjkQXb0-d"
      },
      "source": [
        "Now you should also One-hot encode the **test** (not the predicted ones) labels for both murmur and outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E0LHwnQUb0fV"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "type object 'GradientBoostingClassifier' has no attribute 'compute_scores'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m murmur_scores, outcome_scores \u001b[39m=\u001b[39m cm\u001b[39m.\u001b[39;49mcompute_scores(y_test_murmur_bin,   \u001b[39m# One-hot encoded test labels for murmur eg. [1 0 0]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                   y_pred_murmur_prob,  \u001b[39m# One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                   murmur_classes,      \u001b[39m# As defined before\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                   y_test_outcome_bin,  \u001b[39m# One-hot encoded test labels for outcome eg. [1 0]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                                   y_pred_outcome_prob, \u001b[39m# One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/albertahnlide/Documents/GitHub/BMEN35_exercises/Session6/BMEN35_ensamble_cinc_assignment6.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                                   outcome_classes)     \u001b[39m# As defined before\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'GradientBoostingClassifier' has no attribute 'compute_scores'"
          ]
        }
      ],
      "source": [
        "murmur_scores, outcome_scores = cm.compute_scores(y_test_murmur_bin,   # One-hot encoded test labels for murmur eg. [1 0 0]\n",
        "                                                  y_pred_murmur_prob,  # One-hot encoded predicted probabilities for murmur eg. [0.1 0.7 0.2]\n",
        "                                                  murmur_classes,      # As defined before\n",
        "                                                  y_test_outcome_bin,  # One-hot encoded test labels for outcome eg. [1 0]\n",
        "                                                  y_pred_outcome_prob, # One-hot encoded predicted probabilities for outcome eg. [0.1 0.9]\n",
        "                                                  outcome_classes)     # As defined before\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T91QCcRgcl9T"
      },
      "source": [
        "Now we have calculated a whole bunch of scores for both murmur and outcome. We can print them using the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq_XJnNot7qH"
      },
      "outputs": [],
      "source": [
        "cm.print_scores(murmur_scores, outcome_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGczxkWWR50z"
      },
      "source": [
        "Did you manage to comparable scores to those in the leaderboard as shown in the last slide of the lecture? (It should be noted that we don't have the validation data so we are perhaps comparing apples and oranges). Which set of ensemble classifiers worked the best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5zNz7eZeSvC"
      },
      "source": [
        "## The End"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
